---
title: "model_1"
author: "Sam Temlock"
date: "13/11/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lmtest)
library(sandwich)
library(tidyverse)
library(magrittr)

df <- read.csv("covid-19.csv", header = TRUE)
```

For our first model, we will analyze the relationship between the COVID case rate per 100,000 and the population density per square mile of states. First, we take a look at the distribution of population density per square mile.

```{r}
histogram_of_pdensity <- df %>%
  ggplot(aes(x = Population.density.per.square.miles)) + 
  geom_histogram(bins = 20) + 
  labs(
    title = 'Figure 1. Distribution of Population Density per Square Mile', 
    x = 'Population density per square mile', y = 'Count')

histogram_of_pdensity
```

As we can see from Figure 1, although most of the population density is concentrated in the 0 to 1500 range, we have some grouping of outliers that are very far from this concentration. When we perform an analysis, we see that there is only one data sample that is the outlier, which is the District of Columbia (D.C.). This is given due to the fact that D.C. is a district that solely consists of a large city, as mentioned as a possibility in the introduction. Given that this causes the data to be skewed, we choose to remove this data point from the sample. Once removed, we see that we now have a relatively normal distribution of population densities (see Figure 2).

```{r}
# Find the outlier data points
outliers <- subset(df,Population.density.per.square.miles > 4000)
outliers

# Remove the outlier from the dataset
df_new <- df[ !(df$State %in% outliers$State), ]

# Check to see that D.C. has been removed
paste("Outliers in the new dataframe:", outliers$State %in% df_new$State)

histogram_of_pdensity <- df_new %>%
  ggplot(aes(x = Population.density.per.square.miles)) + 
  geom_histogram(bins = 20) + 
  labs(
    title = 'Figure 2. Distribution of Population Density per Square Mile without D.C.', 
    x = 'Population density per square mile', y = 'Count')

histogram_of_pdensity
```

Next, we evaluate the values for case_rate

```{r variables}

df_new %>% 
  ggplot(aes(x = Case.Rate.per.100000, y = Population.density.per.square.miles)) + 
  geom_point() 

df_new %>% 
  ggplot(aes(x = Death.Rate.per.100000, y = Population.density.per.square.miles)) + 
  geom_point() 
```
```{r}
model_current <- lm(Case.Rate.per.100000 ~ Population.density.per.square.miles , data = df_new, na.action = na.omit)
coeftest(model_current, vcov = vcovHC)

model_alternative <- lm(Death.Rate.per.100000 ~ Population.density.per.square.miles , data = df_new, na.action = na.omit)
coeftest(model_alternative, vcov = vcovHC)
```

```{r}

df<-df%>%
  rename(case_rate_100k = 'Case.Rate.per.100000',
         population_density = 'Population.density.per.square.miles',
         white_pct = 'White...of.Cases',
         black_pct = 'Black...of.Cases',
         hispanic_pct = 'Hispanic...of.Cases',
         other_pct = 'Other...of.Cases',
         mask_public='Mandate.face.mask.use.by.all.individuals.in.public.spaces',
         mask_legal='No.legal.enforcement.of.face.mask.mandate') %>%
  select(case_rate_100k, population_density, white_pct, black_pct, hispanic_pct, 
         other_pct, mask_public, mask_legal)
head(df)
```


You will next build a set of models to investigate your research question, documenting your decisions.  Here are some things to keep in mind during your model building process:

1. *What do you want to measure*?  Make sure you identify one, or a few, variables that will allow you to derive conclusions relevant to your research question, and include those variables in all model specifications.
2. Is your modeling goal one of description or explanation? 
3. What [covariates](https://en.wikipedia.org/wiki/Dependent_and_independent_variables#Statistics_synonyms) help you achieve your modeling goals?  What covariates are problematic, either due to *collinearity*, or because they are outcomes that will absorb some of a causal effect you want to measure?
4. What *transformations*, if any, should you apply to each variable?  These transformations might reveal linearities in scatterplots, make your results relevant, or help you meet model assumptions.
5. Are your choices supported by exploratory data analysis (*EDA*)?  You will likely start with some general EDA to *detect anomalies* (missing values, top-coded variables, etc.).  From then on, your EDA should be interspersed with your model building.  Use visual tools to *guide* your decisions.  You can also leverage statistical *tests* to help assess whether variables, or groups of variables, are improving model fit.

At the same time, it is important to remember that you are not trying to create one perfect model.  You will create several specifications, giving the reader a sense of how robust (or sensitive) your results are to modeling choices, and to show that you're not just cherry-picking the specification that leads to the largest effects.

At a minimum, you should include the following three specifications:

1. **Model 1**: One model with *only the key variables* you want to measure (possibly transformed, as determined by your EDA), and no other covariates (or perhaps one, or at most two, covariates if they are so crucial that it would be unreasonable to omit them)

```{r}
df %>% 
  ggplot(aes(x = case_rate_100k, y = log(population))) + 
  geom_point() 
```

